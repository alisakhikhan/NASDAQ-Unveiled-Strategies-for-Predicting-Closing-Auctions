{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport matplotlib.pyplot as plt\nimport warnings\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nfrom numba import jit, cuda\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport joblib\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-25T02:29:21.464407Z","iopub.execute_input":"2023-11-25T02:29:21.464746Z","iopub.status.idle":"2023-11-25T02:29:25.448716Z","shell.execute_reply.started":"2023-11-25T02:29:21.464720Z","shell.execute_reply":"2023-11-25T02:29:25.447485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models=[]\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ndf = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\nx_test = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T02:59:02.864343Z","iopub.execute_input":"2023-11-25T02:59:02.864657Z","iopub.status.idle":"2023-11-25T02:59:09.704691Z","shell.execute_reply.started":"2023-11-25T02:59:02.864630Z","shell.execute_reply":"2023-11-25T02:59:09.703378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T02:29:48.661701Z","iopub.execute_input":"2023-11-25T02:29:48.662042Z","iopub.status.idle":"2023-11-25T02:29:48.738497Z","shell.execute_reply.started":"2023-11-25T02:29:48.662014Z","shell.execute_reply":"2023-11-25T02:29:48.737423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ndef generic_preprocess(x):\n    x['imbalance_ratio'] = x['imbalance_size'] / x['matched_size']\n    x['bid_ask_volume_diff'] = x['ask_size'] - x['bid_size']\n    x['mid_price'] = (x['ask_price'] + x['bid_price']) / 2\n    x['bid_plus_ask_sizes'] = x['bid_size'] + x['ask_size']\n    if 'time_id' not in x.columns:\n        x['time_id']=[0]*x.shape[0]\n    x['far_price'].fillna(1)\n    x['near_price'].fillna(1)\n    x.drop(['imbalance_size','matched_size','ask_size','bid_size','row_id','time_id'],axis=1,inplace=True)\n    for i in x.columns:\n        if x[i].isnull().sum()>0:\n            x[i].fillna(x[i].mean(),inplace=True)\n    return x\n\n\n\ndef standardize(df):\n    #Standardize by stock ID (each stock is fit to have SD=1 and mean 0)\n    def standardize_stock(group):\n        columns_to_scale = group.columns.difference(['stock_id', 'date_id', 'seconds_in_bucket'])\n        scaler = StandardScaler()\n        group[columns_to_scale] = scaler.fit_transform(group[columns_to_scale])\n        return group\n\n    # Reset index if 'stock_id' is part of the index\n    if 'stock_id' in df.index.names:\n        df = df.reset_index()\n\n    # Apply standardization to each stock group\n    df_scaled = df.groupby('stock_id').apply(standardize_stock)\n\n    # Reset index to flatten the DataFrame after groupby\n    df_scaled = df_scaled.reset_index(drop=True)\n\n    # Sort by 'stock_id', 'date_id', 'seconds_in_bucket'\n\n\n    return df_scaled\n\ndef rolling_average(df):\n    # Define a function to apply the rolling average within each group\n    def apply_rolling(group):\n        # Calculate rolling average without looking ahead\n        rolling_avg = group['reference_price'].rolling(window=10, min_periods=1).mean()\n        # Fill NaN values (for the first 9 elements in each group) with 1\n        rolling_avg.iloc[:9] = 0\n        return rolling_avg\n\n    # Group by 'stock_id' and 'date_id', then apply the rolling function\n    df['rolling_avg'] = df.groupby(['stock_id', 'date_id']).apply(apply_rolling).reset_index(level=[0,1], drop=True)\n\n    return df\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-25T03:16:57.073430Z","iopub.execute_input":"2023-11-25T03:16:57.073891Z","iopub.status.idle":"2023-11-25T03:16:57.084603Z","shell.execute_reply.started":"2023-11-25T03:16:57.073865Z","shell.execute_reply":"2023-11-25T03:16:57.083934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_preprocessing(df):\n    df1 = generic_preprocessing(df)\n    df2 = standardize(df1)\n    df3 = rolling_average(df3)\n    return df3","metadata":{"execution":{"iopub.status.busy":"2023-11-25T03:21:09.165212Z","iopub.execute_input":"2023-11-25T03:21:09.165729Z","iopub.status.idle":"2023-11-25T03:21:09.171599Z","shell.execute_reply.started":"2023-11-25T03:21:09.165697Z","shell.execute_reply":"2023-11-25T03:21:09.170481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df.drop(['target'],axis=1)\nx = data_preprocessing(x)\nx.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T03:18:03.097495Z","iopub.execute_input":"2023-11-25T03:18:03.097945Z","iopub.status.idle":"2023-11-25T03:18:49.974210Z","shell.execute_reply.started":"2023-11-25T03:18:03.097913Z","shell.execute_reply":"2023-11-25T03:18:49.972692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = x_test.copy()\nx=df.drop(['target'],axis=1)\nx = x[x['date_id'] < 478]\n\ny=df[['date_id','target']]\ny = y[y['date_id'] < 478].fillna(0,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T03:22:51.052853Z","iopub.execute_input":"2023-11-25T03:22:51.053263Z","iopub.status.idle":"2023-11-25T03:22:51.710307Z","shell.execute_reply.started":"2023-11-25T03:22:51.053235Z","shell.execute_reply":"2023-11-25T03:22:51.709561Z"},"trusted":true},"execution_count":null,"outputs":[]}]}